# 8 Basfunktionernas derivator

> RE: basfunktioner är ett set av funktioner som aproximerar
> $\left\{ \varphi_i \right\}^N_{i=1}$

**Sats att bevisa**

Derivatan av en basfunktion $\varphi = \hat{\varphi} \circ F_K^{-1}$ ges av:
$\nabla \varphi = (F'_K)^{-\top} \nabla_{\hat{x}} \hat{\varphi} \circ (F'_K)^{-1}$

För att vara utförlig vill vi egentligen visa att det stämmer för alla basfunktioner, men om vi visar att det stämmer för en generisk basfunktion kommer alla andra också funka.
$\forall \varphi \in \left\{ \varphi_i \right\}^N_{i=1}.\quad
\nabla \varphi = (F'_K)^{-\top} \nabla_{\hat{x}} \hat{\varphi} \circ (F'_K)^{-1}$

> RE:
> $\varphi(x) = \hat{\varphi}(F_K^{-1}(x))$
> Där $x$ är en punkt i rummet $\mathbb{R}^n$
> Där $\varphi$ är en av basfunktionen i det rummet vi vill undersöka ($\mathbb{R}^n \to \mathbb{R}^n$)
> Där $\hat{\varphi}$ är korresponderande basfunktionen i referensrummet ($\mathbb{R}^n \to \mathbb{R}^n$)
>
> $F_K^{-1}(x) = \hat{x}$ (och motsvarande $F_K(\hat{x}) = x$)
> $\hat{\varphi}(\hat{x}) = \varphi(x)$

**Bevis**

### **1) Dela upp i mindre delar**

> RE: expandering av $\nabla f(g(x))$
> $\nabla\big( f(g(x)) \big) = \left(
   {\Large\frac{\partial}{\partial x_1}} f(g(x)),\enspace
   {\Large\frac{\partial}{\partial x_2}} f(g(x)),\enspace\dots\enspace,
   {\Large\frac{\partial}{\partial x_n}} f(g(x))
\right)$

Sätt in $f = \hat{\varphi}$ och $g = F_K^{-1}$

$\nabla\varphi = \left(
   {\Large\frac{\partial}{\partial x_1}} \varphi(F_K^{-1}(x)),\enspace
   {\Large\frac{\partial}{\partial x_2}} \varphi(F_K^{-1}(x)),\enspace\dots\enspace,
   {\Large\frac{\partial}{\partial x_n}} \varphi(F_K^{-1}(x))
\right)$

### **2) Undersök $(\nabla\varphi)_i$**
$(\nabla\varphi)_i = {\Large\frac{\partial}{\partial x_i}} \varphi(x) = {\Large\frac{\partial}{\partial x_i}} \hat{\varphi}(F_K^{-1}(x))$

> RE: kedjeregeln för partiella
> ${\Large\frac{\partial}{\partial x_i}}f(g(x)) =
\displaystyle\sum_{i=1}^N {\frac{\partial f}{\partial y_i}}(g(x)) \cdot \frac{\partial g_j}{\partial x_i}$
> Där $g(x) = y$

Applicera kedjeregeln:
$= \displaystyle\sum_{j=1}^N
   {\frac{\partial\hat{\varphi}}{\partial {\large \hat{x}_j}} (F_K^{-1}(x))}
   \cdot
   {\frac{\partial(F_K^{-1})_j}{\partial {\large x_i}}}
$

> RE: jakobi
> $f'(x) = J_f(x) = Df(x) = \nabla f(x)$
>
> Exempel:
>> funktions defintion
>> $f \in \mathbb{R}^3 \to \mathbb{R}^2$
>
>> Alternativ ekvivalent definition:
>> $f(x) = y$
>> $x \in \mathbb{R}^3$
>> $y \in \mathbb{R}^2$
>
> $f' = \begin{bmatrix}
\frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \frac{\partial f_1}{\partial x_3}
\\
\frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \frac{\partial f_2}{\partial x_3}
> \end{bmatrix}$
>
> $\Large f'_{ij} = \frac{\partial f_i}{\partial x_j}$
>
> $\Large f'_{i} = \begin{bmatrix}
\frac{\partial f_i}{\partial x_1}&
\frac{\partial f_i}{\partial x_2}&
\frac{\partial f_i}{\partial x_3}
\end{bmatrix} = (f_i)'$
>
> $\Large (f'^\top)_{i} = \begin{bmatrix}
\frac{\partial f_1}{\partial x_i}&
\frac{\partial f_2}{\partial x_i}
\end{bmatrix}$

Substituera med jakobimatris
$= \displaystyle\sum_{j=1}^N
   \Big(
      \hat{\varphi}'(F_K^{-1}(x))
   \Big)_j
   \cdot
   (F_K^{-1})'_{ji}
$
> ⚠️ Notera att $\hat{\varphi}'$ är jacobimastrisen med avsende av $\hat{x}$ medans $(F_K^{-1})'$ är på avsende av vanliga $x$!

> RE: Kovertering mellan matrismultiplikation och summor
> $A \in \mathbb{R}^{m \times n}$, $B \in \mathbb{R}^{n \times w}$
>
> $(A \cdot B)_i = \displaystyle\sum_{k\in\mathbb{K}} A_{ik} \cdot B_{k}$
>
> motsvarande vid transponering (och $A \in \mathbb{R}^{n \times m}$ istället):
> $(A^\top \cdot B)_i = \displaystyle\sum_{k\in\mathbb{K}} A_{ki} \cdot B_{k}$

Summeringen kan göras om till en matrismultiplication

$(\nabla\varphi)_i = \left(
   \left(
      \left(
         F_K^{-1}
      \right)'
   \right)^\top
   \cdot
   \hat{\varphi}'
   \left(
      F_K^{-1}(x)
   \right)
\right)_i$

Skriv om med inversa funktionssatsen

> RE: Inversa funktionssatsen (enl. wikipedia)
> om $F(a) = b$ kan Jakobimatisen till $F^{-1}$ beräknas med:
> $(F^{-1})'(b) = (F'(a))^{-1}$

> RE:
> $F_K^{-1}(x) = \hat{x}$
> $F_K(\hat{x}) = x$

$(F_K^{-1})'(x) = (F_K'(\hat{x}))^{-1}$

$(\nabla\varphi)_i = \left(
   \left(F_K'\right)^{-\top}
   \cdot
   \hat{\varphi}'
   \left(F_K^{-1}(x)\right)
\right)_i$


> ⚠️ $\hat{\varphi}'$ är fortfarande jacobimastrisen med avsende av $\hat{x}$
men nu när vi har applicerat inversa funktionssatsen är $F_K'$ är nu också avsende av $\hat{x}$!

### **3) Undersök $\nabla\varphi$**

Vi har visat att följande stämmer för alla i
$(\nabla\varphi)_i = \left(
   \left(F_K'\right)^{-\top}
   \cdot
   \hat{\varphi}'
   \left(F_K^{-1}(x)\right)
\right)_i$

$\nabla\varphi =
   \left(F_K'\right)^{-\top}
   \cdot
   \hat{\varphi}'
   \left(F_K^{-1}(x)\right)
$

En sista substitution vi vill göra är att använda $\nabla$ notation istället för jakobi apostrof.

$\nabla\varphi =
   (F_K')^{-\top}
   \cdot
   \nabla_{\hat{x}}\varphi'
   (F_K^{-1}(x))
$
$\nabla\varphi = (F_K')^{-\top} \cdot \nabla_{\hat{x}}\varphi \circ F_K^{-1}$

Vilket är det vi ville bevisa!

> ⚠️ $F_K'$ är fortfarande jacobimastrisen med avsende av $\hat{x}$

$\nabla\varphi =
   (\nabla_{\hat{x}}F_K)^{-\top}
   \cdot
   \nabla_{\hat{x}}\varphi'
   (F_K^{-1}(x))
$


# **9 Satsen om bästa aproximation**

**Sats att bevisa**
> Sats 5.2. Låt $V$ vara ett linjärt tum och $V_h \sub V$ ett underrunm. För varje $f$ i $V$ är den ortogonala projektioonen $P_hf$ den bästa aproximationen i $L^2$-normen, dvs.
> $\lVert f- P_hf\rVert  \le \lVert f-v \rVert$
> för alla $v \in V_h$
>> *Inklusive när $v$ är den närmaste punkten i $V_h$ (Altså den bästa aproximationen)*

> RE:
> $P_h \in \mathbb{R}^{k\times k}$
> $f \in \mathbb{R}^{k}$

## **Bevis**
### **1) Start**
Vi börjar med att betrakta kvadraten av felet

$\lVert f-P_hf\rVert^2$
$= \braket{f-P_hf, f-P_hf}$
Lägg till ett godtyckligt fel $q$ i $V_h$
$= \braket{f-P_hf, f-q+q-P_hf}$

> RE:
> $\braket{A,B+C} = \braket{A,B} + \braket{A,C}$

$= \braket{f-P_hf, f-q} + \braket{f-P_hf, q-P_hf}$

### **2) Förenkla bort ortogonala**
Vad innebär detta uttryck? låt oss betrakta ett visuellt exempel i $\mathbb{R}^3$ där $V_h$ är ett underrum definierat som spannet av två vektorer $v_1$ och $v_2$.

![alt text](images/aproximation.png)

### **2.1) Om $f \in V_h$**
Då får vi $P_hf = f$ och projektionsfelet blir $0$.
$\braket{f-P_hf, q-P_hf} = \braket{\bold{0}, q-P_hf} = 0$

### **2.2) Om $f \not\in V_h$**
Då $P_hf \in V_h$ och $f \not\in V_h$ måste $f-P_hf$ vara ortogonalt till $V_h$.
Då $q, P_hf \in V_h$ kommer även $q-P_hf \in V_h$.
Då skalärprodukten av ortagonala vektorer är $0$ får vi:

$\braket{f-P_hf, q-P_hf} = 0$

### **3) Relatera tillbaka till frågan**
Genom 2.1 eller 2.2 får vi:

$\braket{f-P_hf, q-P_hf} = 0$

> ⚠️ Även om bildexemplet var för 3 dimensioner funkar textresonemanget för andra rum.

och således:
$\lVert f-P_h\rVert^2$
$=\braket{f-P_hf, f-q} + \underbrace{\braket{f-P_hf, q-P_hf}}_0$
$= \braket{f-P_hf, f-q}$

> RE: Cauchy–Schwarz olikhet
> $|\braket{a, b}|^2 \le \braket{a, a}\braket{b, b}$
> $|\braket{a, b}| \le \lVert a\rVert \cdot\lVert b\rVert$

Applicera Cauchy–Schwarz olikhet
$\braket{f-P_hf, f-q} \le \lVert f-P_hf \rVert \cdot \lVert f-q \rVert$
$\lVert f-P_hf\rVert ^2 \le \lVert f-P_hf\rVert \cdot \lVert f-q\rVert$

Förenkla
$\lVert f-P_hf\rVert  \le \lVert f-q\rVert$

Då $q$ var en godtycklig punkt i $V_h$ får vi
$\forall q \in V_h.\quad \lVert f-P_h\rVert  \le \lVert f-q\rVert$

Vilket är det vi ville bevisa!.



# **10 Feluppskattning för finita elementmetoden**
**Sats att bevisa**

> Finita elementlösningen $u_h$ från definition 6.3 med homogena Diruchlet-vilkor och $\kappa = 1$ uppfyller fekupskattningen:
> $$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)} \le C\lVert hD^2u\rVert _{L^2(\Omega)}$$
> där $C$ är en konstant som beror på minsta vinkeln av cellerna $K$ i nätet $\mathscr{K}$
>
>> RE: Homogena Dirichlet-villkor
>> $u = 0$ längs randen av området $\Omega$
>> $\Gamma_R = \emptyset\enspace$ ( $\Gamma_R$ är tom)
>> $V_{h,D} = V_{h,0}$

> RE: $\lVert x \rVert _{L^2(\Omega)}$
> $\lVert x \rVert _{L^2(\Omega)} = \sqrt{\int_\Omega|x|^2dx}$
> $\lVert x \rVert _{L^2(\Omega)}^2 = \int_\Omega|x|^2dx$

> RE:
> $u$ är exakta lösningen
> $u_h$ är lösningen aproximerad med nätstorleken $h$

## **Bevis**
### **1) Start**
Vi, likt förra uppgiften, med att betrakta kvadraten av felet

$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)}^2$
$=\int_\Omega \lvert \nabla(u-u_h) \rvert^2dx$

> RE:
$\large \lvert \nabla f \rvert^2
= \large \lVert \nabla f \rVert^2
= (\frac{\partial f}{\partial x_1})^2 + (\frac{\partial f}{\partial x_2})^2 + \cdots$

$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(u-u_h)} dx$

> RE: Skalärprodukt av radvektorer är också väldefinierad
> $A,B \in \mathbb{R}^{k\times 1}$
> $\braket{A,B} = \braket{A^\top,\enspace B^\top}$

### **2) Introducera godtyckligt fel**
Vi introducerar ingen ett godtyckligt fel $v$ men denna gång låter vi felet vara från $V_{h,D}$

> RE:
> $V_{h}$ delmängen där alla element befinner sig på nätet
> $V_{D}$ delmängen där alla element upfyller Dirilect-vilktoret
> $V_{h,D}$ delmängen där alla element befinner sig på nätet och upfyller Dirilect-vilktoret.

$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace
\nabla(u-v+v-u_h)} dx$

$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace
\nabla(u-v)+\nabla(v-u_h)} dx$

$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(u-v)} + \braket{\nabla(u-u_h),\enspace \nabla(v-u_h)} dx$

$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(u-v)} dx +\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(v-u_h)} dx$

### **3) Ta bort ortagonala\* delar**
> RE:
> Finita elementlösningen $u_h$ från definition 6.3 uppfyller *Galerkin-ortogonaliteten*
> $$\int_\Omega \kappa \nabla(u-u_h) \cdot \nabla v dx + \int_{\Gamma_R}\gamma(u-u_h)v d\bold{s} = 0$$
> för alla $v \in V_{h,0}$
>
>> RE:
>> $V_{h,0} \sub V_0$

Då vi förutsätter homogena Dirilect-vilkor har vi $\Gamma_R = \emptyset$ och $V_{h,D} = V_{h,0}$ får vi en mycket enklare version av Galerkin-ortogonalitet:

$\displaystyle\int_\Omega \kappa \nabla(u-u_h) \cdot \nabla v dx = 0\quad$ för alla $v \in V_{h,D}$

Detta medför att om $v-u_h \in V_{h,D}$ kan vi byta ut högra delen av summan med 0
### **3.1) Stämmer $v-u_h \in V_{h,D}$?**
> RE: $V_{h,D} = V_{h,0}$

$v$ är definierat som att vara del av $V_{h,D}$ men i vårat fall är detta ekvivalent med $v \in V_{h,0}$
$u_h$ är definierat som den aproximativa lösningen som ligger på nätet $(V_{h,D})$ men i vårat fall har vi igen bestämmt att alla $u$ kommer upfylla Dirilecht-vilkoret och får $u_h \in V_{h,0}$

Altså: $v, u_h \in V_{h,D} \iff v, u_h \in V_{h,0}$

Då $V_{h,D}$ är delrum gäller $\forall x,y \in V.\quad (\lambda_ax + \lambda_by) \in V$

Således är $v-u_h \in V_{h,D}$ och med detta kan vi använda Galerkin-ortogonalitet för att förenkla bort delar av utrrycket.

### **4) Formulera om mha Cauchy–Schwarz**
Vi tar nu bort den ortagonala delen av summan och får:

$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)}^2$
$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(u-v)} dx +\underbrace{\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(v-u_h)}}_{0} dx$
$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(u-v)} dx$

> RE: Cauchy–Schwarz olikhet (2019 boken)
> $\braket{p, q}^2 \le \braket{p, p}\braket{q, q}$
> $|\braket{p, q}| \le \lVert p \rVert \cdot\lVert q \rVert$

Vi vill nu baka in Cauchy–Schwarz olikhet i integralen genom att göra följande transformation
$\left\lvert \displaystyle\int_\Omega \braket{f,\ g} dx \ \right\rvert \le
       \sqrt{\displaystyle\int_\Omega \braket{f,\ f} dx}
       \sqrt{\displaystyle\int_\Omega \braket{g,\ g} dx}$

> ⚠️ Detta påstående är inte bevisat i (2019) Boken och jag anser inte det inte är trivialt, nästa sektion kommer att bevisa att detta påstende är korrekt.
### **4.1) Cauchy–Schwarz över integral**

Låt definera en funktion $h(t)$
$= \displaystyle\int_\Omega \braket{tf(x) + b(x),\ tf(x) + b(x)}dx$

En viktig observation att göra är att $h(t)$ alltid kommer ha samma tecken oavsett $t$, skalärprodukten med sig själv är alltid positiv vilket betyder att det enda som bestämmet tecknet är hur $\Omega$ är "riktad".

$= \displaystyle\int_\Omega \Big( t^2\braket{f(x), f(x)} + 2t\braket{f(x), g(x)} + \braket{g(x), g(x)} \Big) dx$

$= t^2\int_\Omega \braket{f(x), f(x)}dx + 2t\int_\Omega \braket{f(x), g(x)}dx + \int_\Omega \braket{g(x), g(x)}dx$

Låt förenkla genom att introducera:
$A = \int_\Omega \braket{f(x), f(x)}dx$
$B = \int_\Omega \braket{f(x), g(x)}dx$
$C = \int_\Omega \braket{g(x), g(x)}dx$

$h(t) = At^2 + 2Bt + C$

> RE: $h(t)$ måste ha samma tecken oberoende av $t$!

Ett annat sett att formulera detta är att
$t = \displaystyle\frac{-2B \pm \sqrt{4B^2-4AC}}{2A}$
Inte får fler än en reel lösning. (Om det hade funnits två olika rötter kommer kurvan mellan de två punkterna ha annat tecken än runtliggande)

För att garantera detta räcker det att $4B^2-4AC \le 0$
$\iff B^2-AC \le 0$
$\iff B^2 \le AC$

Om vi substituerar tillbaka innebörden av $A,B,C$ får vi:

$\left(\displaystyle\int_\Omega \braket{f(x), g(x)}dx\right)^2 \le \displaystyle\int_\Omega \braket{f(x), f(x)}dx\displaystyle\int_\Omega \braket{g(x), g(x)}dx$

Från detta följer:
$\left\lvert \displaystyle\int_\Omega \braket{f,\ g} dx \ \right\rvert \le
       \sqrt{\displaystyle\int_\Omega \braket{f,\ f} dx}
       \sqrt{\displaystyle\int_\Omega \braket{g,\ g} dx}$

vilket avsutar denna lilla avstickare.

### **4.2) Formulera klart mha Cauchy–Schwarz**

$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)}^2$
$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(u-v)} dx$
$\le \sqrt{\displaystyle\int_\Omega \braket{\nabla(u-u_h),\ \nabla(u-u_h)} dx}
\sqrt{\displaystyle\int_\Omega \braket{\nabla(u-v  ),\ \nabla(u-v  )} dx}$

### **5) Förenkla bort kvadraten**

Skriv om som norm istället för skalärpordukt med sig själv.
$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)}^2 \le
\sqrt{\displaystyle\int_\Omega |\nabla(u-u_h)|^2 dx}
\sqrt{\displaystyle\int_\Omega |\nabla(u-v)|^2 dx}$

Skriv om mha. definitionen av $\lVert f \rVert _{L^2(\Omega)}$
$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)}^2 \le
\lVert u-u_h \rVert _{L^2(\Omega)} \cdot
\lVert u-v   \rVert _{L^2(\Omega)}$

Förenkla de delar som finns på bägge sidor
$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)} \le
\lVert u-v \rVert _{L^2(\Omega)}$

### **6) Interpretation**
$\forall v \in V_{h,0}.\quad \lVert \nabla(u-u_h) \rVert _{L^2(\Omega)} \le$ $\lVert u-v \rVert _{L^2(\Omega)}$

Med andra ord så får vi att aproximationsfelet är $\le$ avståndet mellan det korrekta värdet $u$ och den närmaste $V_{h,0}$ som existerar.

> RE: $V_{h,0} = V_{h,D}$

Om vi väljer $v = \pi_hu$ får vi
$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)} \le$ $\lVert u-\pi_u u \rVert _{L^2(\Omega)}$

> RE: interpolationsfelsuppskattningen (5.164)
$\lVert u-\pi_u u \rVert _{L^2(\Omega)} \le C\lVert hD^2u\rVert _{L^2(\Omega)}$

> ⚠️ 2019 boken har inte med någon motsvarande formen, jag förutsätter att det är detta som står?

$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)} \le C\lVert hD^2u\rVert _{L^2(\Omega)}$

Vilket är det vi ville visa.

### **7) Sammanfattning**

Vi började med att betrakta kvadraten av felet och
$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)}^2$

Genom att inroducera +/- ett godtyckligt fel från $V_{h,D}$ kunde vi detta hitta en ekvivalent definition till kvadraten av felet. Detta nya uttryck gick sen förenkla genom Galerkin-ortogonalitet.

$=\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(u-v)} dx +\underbrace{\displaystyle\int_\Omega \braket{\nabla(u-u_h),\enspace \nabla(v-u_h)}}_{0} dx$
Vi bevisade sen att
$\left\lvert \displaystyle\int_\Omega \braket{f,\ g} dx \ \right\rvert \le
       \sqrt{\displaystyle\int_\Omega \braket{f,\ f} dx}
       \sqrt{\displaystyle\int_\Omega \braket{g,\ g} dx}$

Och genom detta kunde vi hitta en olikhet.
$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)}^2 \le
\sqrt{\displaystyle\int_\Omega |\nabla(u-u_h)|^2 dx}
\sqrt{\displaystyle\int_\Omega |\nabla(u-v)|^2 dx}$

Detta uttryck gick att förenkla för att nå.
$\forall v \in V_{h,0}.\quad \lVert \nabla(u-u_h) \rVert _{L^2(\Omega)} \le$ $\lVert u-v \rVert _{L^2(\Omega)}$

Om vi sist väljer $v = \pi_hu$ får vi:
$\lVert \nabla(u-u_h) \rVert _{L^2(\Omega)} \le C\lVert hD^2u\rVert _{L^2(\Omega)}$